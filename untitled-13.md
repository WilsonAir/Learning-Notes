# Learning Fine-Grained Image Similarity with Deep Ranking

**14、Learning Fine-Grained Image Similarity with Deep Ranking**

[https://medium.com/@akarshzingade/image-similarity-using-deep-ranking-c1bd83855978](https://medium.com/@akarshzingade/image-similarity-using-deep-ranking-c1bd83855978)

* 什么是图片相似性
* 怎么建立一个相似性模型
* 三联
* 与图像分类工作的区别
* 怎么测量两个图片的相似性

在自然图像中，通常使用L1规范，也就是曼哈顿距离来代替图像相似性的概念，在深度学习排序中，作者使用欧式距离的平方来作为图像的相似性度量，距离越短，两个图像相似度越高。

**概述：**

我们的目标是学习图像相似度模型。我们根据图像嵌入空间中的平方欧几里德距离来定义两个图像P和Q的相似度：

![Screenshot from 2019-08-05 15-30-47.png](.gitbook/assets/0%20%285%29.png)

其中f\(.\)是将图像映射到欧几里德空间中的点的图像嵌入函数，D\( . , . \)是此空间中的欧几里德距离的平方。距离D\( P , Q \)越小，两个图像P和Q越相似。该定义将欧几里德空间中的相似图像排序问题表述为最近邻搜索问题，可以通过近似最近邻搜索算法有效地求解。

我们采用成对排名模型来学习图像相似性排序模型，部分动机由\[3,19\]。假设我们有一组图像P，并且 r\_i,j = r\(pi, pj \) 是成对相关性得分，其表示图像 p\_i ∈ P 和 p\_j ∈ P 的相似程度。两个图像越相似，其相关性得分越高。我们的目标是学习一个嵌入函数f\(.\)，它将更小的距离分配给更相似的图像对，可以表示为：

我们将 t\_i 称为三元组，其中右边分别是查询图像，正图像和负图像。三元组表征图像的相对相似性排序顺序。我们可以为三元组定义以下hinge loss：

![Screenshot from 2019-08-05 15-32-35.png](.gitbook/assets/1%20%281%29.png)

其中g是一个间隙参数，用于规范两个图像对的距离之间的差距：\(pi , pi +\) 和 \( pi, pi - \)。铰链损失是0-1排序误差损失的凸近似，它测量模型违反三元组中指定的排序顺序。我们的目标是：

![APHLATEX215.jpeg](.gitbook/assets/2%20%284%29.jpeg)

（4）

其中λ是一个正则化参数，它控制学习级别的边缘以改善其泛化。W是嵌入函数 f \(.\) 的参数。我们在本文中使用了 λ = 0.001。 （4）可以通过替换 ξ\_i = max{0, g + D\(f\( p\_i \), f\( p^+\_i \)\) − D\(f\( p\_i \), f\( p^−\_i \)\)}转换为无约束优化。

**在这个模型中，最关键的部分是学习图像嵌入函数 f \( . \)。**传统方法通常采用手工制作的视觉特征，并学习线性或非线性变换以获得图像嵌入功能。在本文中，我们采用深度学习技术直接从图像学习图像相似性模型。我们将在（4）中描述基于三重排序损失函数的网络体系结构，以及在以下部分中最小化该目标函数的有效优化算法。

**网络架构**

基于三元组的网络架构被提出用于排名损失函数（4），如图2所示。该净图像图2.深度排序模型的网络架构。

![table\_2\_2\_0.jpeg](.gitbook/assets/3%20%282%29.jpeg)

这个网络以图像三联体为输入。一个图像三元组包含查询图像 p\_i ，正图像p\_i^+ 和负图像 p\_i^-，它们被独立地馈送到具有共享架构和参数的三个相同的深度神经网络f\( . \)中。三元组表征三个图像的相对相似性关系。深度神经网络f\( . \)计算图像p\_i：f\(p\_i\) ∈R^d 的嵌入，其中d是要素嵌入的维度。

**顶部的排名层**评估三联体的铰链损失（3）。排名图层没有任何参数。在学习期间，它评估模型违反排名顺序，并将梯度反向传播到较低层，以便较低层可以调整其参数以最小化排名损失（3）。

我们设计了一种新颖的多尺度深度神经网络结构，它采用不同尺度的不同水平的不变性，受\[8\]的启发，如图3所示。这个图中的ConvNet与\[15\]中的卷积深度神经网络具有相同的结构。ConvNet编码强不变性并捕获图像语义。网络的另外两个部分采用下采样图像并使用较浅的网络架构。这两个部分具有较少的不变性并捕捉视觉外观。最后，我们将这三个部分的嵌入规范化，并将它们与线性嵌入层相结合。在本文中，嵌入的维数是4096。

我们从每个网络的卷积网络（ConvNet）架构开始，最近ConvNet在图像分类的可扩展性和普遍性方面取得了成功\[15\]。ConvNet包含堆叠卷积层，最大池化层，局部归一化层和完全连接层。读者可以参考\[15\]或补充材料了解更多细节。

**卷积层**将图像或另一层的特征映射作为输入，将其与一组k个可学习的内核卷积，并通过激活函数生成k个特征映射。卷积层可以被认为是一组局部特征检测器。

**最大池化层**在像素周围的局部邻域上执行最大池化。最大池层使特征图对小翻译具有鲁棒性。

**局部归一化层**对局部邻域周围的特征映射进行归一化，以具有单位范数和零均值。它导致特征贴图对照明和对比度的差异具有鲁棒性。

**堆叠卷积层**，**最大池化层**和**局部归一化层**充当平移和对比强健局部特征检测器。**完全连接的层**根据这些局部特征检测器的特征图计算非线性变换。

尽管ConvNet在图像分类方面取得了非常好的性能，但其架构中编码的强不变性对于细粒度的图像相似性任务可能是有害的。实验表明，多尺度网络架构在细粒度图像相似性任务中优于单尺度ConvNet。

**优化**

为了避免过度拟合，期望利用各种各样的图像。但是，随着图像数量的增加，可能的三元组数量会立即增加。使用所有三元组在计算上是禁止的和次优的。例如，本文中的训练数据集包含1200万个图像。此数据集中所有可能的三元组的数量大约为 \(1.2×10^7\)^3 = 1.728×10^21。这是一个无法枚举的极大数字。如果采用所提出的三元组采样算法，我们发现优化收敛了大约2400万个三元组样本，这比我们数据集中可能的三元组数量要小很多。

**选择有效的三元组抽样策略来选择最重要的三元组**进行排名学习至关重要。三元组的均匀采样是次优的，因为我们对排名模型返回的排名靠前的结果更感兴趣。在本文中，我们采用在线重要性抽样方案来对三元组进行抽样。

假设我们有一组图像P，它们的成对相关性得分为r\_i,j = r\(pi, pj \) 。每个图像 p\_i 属于一个类别，由 c\_i 表示。让 r\_i 图像的总相关性得分定义为

![Screenshot from 2019-08-05 15-35-48.png](.gitbook/assets/4%20%285%29.png)

p\_i 图像的总相关性得分反映了图像在与同一类别中其他图像的相关性方面的相关性。

为了对三元组进行采样，我们首先根据P的**总相关性得分**从P中对查询图像 p\_i 进行采样。选择图像作为查询图像的概率与其总相关性得分成比例。

然后，我们从与 p\_i 共享相同类别的图像中采样正图像p^+\_i。由于我们对排名靠前的图像更感兴趣，因此我们应该使用高相关性分数r\_i, i+来采样更多正面图像p^+\_i 。选择图像p^+\_i 作为正图像的概率为：其中 T\_p 是阈值参数，并且归一化常数 Z\_i 等于 ∑ \_ i^+ P\(p^+\_i \) ，用于与 p\_i 共享相同类别的所有 p^+\_i 。

![Screenshot from 2019-08-05 15-36-32.png](.gitbook/assets/5%20%287%29.png)

我们有两种类型的负像样本。第一种类型是类外的负样本，它们是与查询图像 p\_i 不同类别的负样本。它们使用p\_i 从具有不同类别的所有图像中均匀绘制。第二种类型是类内负样本，它是与p\_i 属于同一类别的负样本，但与p\_i 的相关性低于p\_i ^ + 。由于我们对排名靠前的图像更感兴趣，因此我们使用与（7）相同的分布绘制inclass负样本 p\_i^ - 。为了确保p\_i ^ +和p\_i ^ -在三元组 t\_i = \(p\_i, p^+\_i , p^−\_i \)中的鲁棒排序，我们还要求相关性分数r\_i,i+ 和r\_i,i-之间的差值应大于T\_r ，即

![Screenshot from 2019-08-05 15-39-00.png](.gitbook/assets/6%20%286%29.png)

我们拒绝不满足这种条件的三元组。如果一个示例的故障路径数超过给定阈值，我们只是丢弃此示例。

学习深度排名模型需要大量数据，这些数据无法加载到主存储器中。需要随机访问数据集中所有示例的采样算法不适用。在本节中，我们提出了一种基于储层采样的高效在线三元组采样算法\[7\]。

我们有一组缓冲区来存储图像。每个缓冲区都具有固定容量，并存储来自同一类别的图像。当我们有一个新图像 p\_j 时，我们计算其关键字 k\_j = u^\(1/rj \)\_j，其中 r\_j 是在（6）中定义的总相关性得分，u\_j = uniform\( 0, 1 \) 是统一采样数。对应于图像 p\_j 的缓冲区可以根据其类别c\_ j找到。如果缓冲区未满，我们将图像p\_ j插入缓冲区，键为k\_ j。否则，我们在缓冲区中找到具有最小键k\_j ^' 的图像 p\_j ^'。如果是k\_j &gt; k\_j ' ，我们将图像 p\_j' 替换为缓冲区中的图像 p\_ j。否则，丢弃imgage示例p\_j。如果采用这种替换方案，则从缓冲区中均匀采样相当于抽取概率与总相关性得分 r\_j 成比例的样本。

从c\_j 类别的缓冲区中的所有图像中均匀地采样一个图像p\_j作为查询图像。然后，我们从c\_ j 类别缓冲区中的所有图像中均匀生成一个图像p\_i ^ +，并以概率min\(1, r\_\(i,i+\) / r\_\(i+\)\) 接受它，该概率对应于采样概率（7）。继续采样，直到接受一个例子。该图像示例用作正图像。

![Screenshot from 2019-08-05 15-42-27.png](.gitbook/assets/7%20%281%29.png)

_图4.在线三元组采样算法的图示。此示例中的负面图像是一种类外的否定。我们为每个类别都有一个缓冲区。当我们得到一个新的图像样本时，我们以规定的概率将其插入到相应类别的缓冲区中。查询和正例从同一缓冲区采样，而负图像从不同的缓冲区采样。_

最后，我们绘制一个负像图样。如果我们绘制出类外的负图像样本，我们将从其他缓冲区中的所有图像中均匀地绘制图像p\_i ^ - 。如果我们正在绘制类内负像样本，我们使用正例的绘图方法来生成负样本，并且只有在满足边际约束时才接受负样本（8）。我们是否采样课堂内或课外阴性样本是由一个外类样本比率参数控制的。该采样方法的示意图如图4所示。油藏重要性采样算法的概述显示在补充材料中。

